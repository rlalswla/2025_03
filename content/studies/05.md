---
id: 5
title: "Custom Query Caching for Server State Management"
description: "Building a React Query inspired caching system for efficient server state management"
publishedDate: "January 2025"
tags: ["Caching","React","State Management","Performance Optimization"]
url: "https://github.com/softeer5th/Team7-BungeoBbang/wiki/%EC%BF%BC%EB%A6%AC-%EC%BA%90%EC%8B%B1%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-%EC%84%9C%EB%B2%84-%EC%83%81%ED%83%9C%EA%B4%80%EB%A6%AC"
locale: "en"
---


        Developed a custom caching system inspired by React Query (TanStack Query) to efficiently manage server state in the ON:U project.
        
        Traditional approaches to fetching and caching data in React applications often lead to inconsistent UI states,
        redundant API calls, and complex state management logic spread across components. To solve these issues,
        I implemented a custom solution that draws inspiration from React Query's core concepts.
        
        The system provides:
        1. Automatic caching of API responses
        2. Configurable stale time and cache invalidation
        3. Deduplication of requests made in rapid succession
        4. Background refetching of stale data
        5. Loading and error states management
        6. Cache persistence through multiple layers (memory, sessionStorage)
        
        The implementation uses a combination of React hooks, context API, and a custom cache store to provide
        a comprehensive solution that maintains consistent data across the application while minimizing
        unnecessary network requests.
      

## Key Takeaways

- Custom hooks for data fetching with built-in caching
- Multi-layer caching strategy (memory and sessionStorage)
- Request deduplication and batching
- Automatic background data refreshing
- Optimistic UI updates for mutations
- Normalized cache for relational data


## Code Example

```typescript

// Custom query hook implementation
import { useState, useEffect, useRef } from 'react';

// Cache store
const queryCache = {
  data: new Map(),
  subscriptions: new Map(),
  
  get(key) {
    return this.data.get(key);
  },
  
  set(key, value, staleTime = 60000) {
    const entry = {
      data: value,
      timestamp: Date.now(),
      staleTime,
      subscribers: 0
    };
    
    this.data.set(key, entry);
    
    // Notify subscribers
    if (this.subscriptions.has(key)) {
      this.subscriptions.get(key).forEach(callback => callback(value));
    }
    
    // Save to sessionStorage if possible
    try {
      sessionStorage.setItem(
        `query_${key}`, 
        JSON.stringify({ data: value, timestamp: entry.timestamp })
      );
    } catch (err) {
      // Handle storage errors
    }
  },
  
  subscribe(key, callback) {
    if (!this.subscriptions.has(key)) {
      this.subscriptions.set(key, new Set());
    }
    this.subscriptions.get(key).add(callback);
    
    // Increment subscriber count
    const entry = this.data.get(key);
    if (entry) {
      entry.subscribers += 1;
    }
    
    return () => {
      // Unsubscribe and clean up if needed
      const subs = this.subscriptions.get(key);
      if (subs) {
        subs.delete(callback);
        
        if (entry) {
          entry.subscribers -= 1;
          
          // Clean up cache if no subscribers and data is stale
          if (entry.subscribers === 0 && this.isStale(key)) {
            this.data.delete(key);
          }
        }
      }
    };
  },
  
  isStale(key) {
    const entry = this.data.get(key);
    if (!entry) return true;
    
    return Date.now() - entry.timestamp > entry.staleTime;
  }
};

// Custom hook
export function useCustomQuery(queryKey, queryFn, options = {}) {
  const {
    staleTime = 60000,
    enabled = true,
    onSuccess,
    onError,
    initialData
  } = options;
  
  const [data, setData] = useState(() => {
    // Check cache first
    const cached = queryCache.get(queryKey);
    if (cached) return cached.data;
    
    // Then check sessionStorage
    try {
      const stored = sessionStorage.getItem(`query_${queryKey}`);
      if (stored) {
        const parsed = JSON.parse(stored);
        // Only use if not stale
        if (Date.now() - parsed.timestamp <= staleTime) {
          return parsed.data;
        }
      }
    } catch (err) {
      // Ignore storage errors
    }
    
    return initialData;
  });
  
  const [isLoading, setIsLoading] = useState(false);
  const [error, setError] = useState(null);
  const isFetchingRef = useRef(false);
  
  // Function to fetch data
  const fetchData = async () => {
    if (isFetchingRef.current) return;
    
    isFetchingRef.current = true;
    setIsLoading(true);
    
    try {
      const result = await queryFn();
      setData(result);
      setError(null);
      
      // Update cache
      queryCache.set(queryKey, result, staleTime);
      
      if (onSuccess) onSuccess(result);
    } catch (err) {
      setError(err);
      if (onError) onError(err);
    } finally {
      setIsLoading(false);
      isFetchingRef.current = false;
    }
  };
  
  // Subscribe to cache updates
  useEffect(() => {
    if (!enabled) return;
    
    const unsubscribe = queryCache.subscribe(queryKey, (newData) => {
      setData(newData);
    });
    
    return unsubscribe;
  }, [queryKey, enabled]);
  
  // Fetch or use cache
  useEffect(() => {
    if (!enabled) return;
    
    const cached = queryCache.get(queryKey);
    
    if (!cached || queryCache.isStale(queryKey)) {
      fetchData();
    }
  }, [queryKey, enabled]);
  
  // Refetch function
  const refetch = () => fetchData();
  
  return { data, isLoading, error, refetch };
}
      
```


## Application

This custom caching system was implemented in the ON:U chat platform to efficiently manage real-time conversation data. It significantly reduced redundant API calls and ensured that all components displayed consistent data. The caching layer was particularly valuable for optimizing the performance of chat screens where multiple components needed access to the same conversation data.

